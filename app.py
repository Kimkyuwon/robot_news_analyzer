import streamlit as st
import google.generativeai as genai
from duckduckgo_search import DDGS
from datetime import datetime, timedelta
import time
import os
import PyPDF2
import io
import json
from docx import Document
from docx.oxml.ns import qn
from fpdf import FPDF

# Page configuration
st.set_page_config(
    page_title="ë¡œë´‡ ì‚°ì—… ì£¼ê°„ ë¶„ì„ ë¦¬í¬íŠ¸",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for mobile responsiveness and better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #ff7f0e;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 3px solid #ff7f0e;
        padding-bottom: 0.5rem;
    }
    .news-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border-left: 4px solid #1f77b4;
    }
    .news-title {
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 0.5rem;
    }
    .news-snippet {
        color: #555;
        font-size: 0.9rem;
        margin-bottom: 0.5rem;
    }
    .news-link {
        font-size: 0.85rem;
        color: #1f77b4;
    }
    @media (max-width: 768px) {
        .main-header {
            font-size: 1.8rem;
        }
        .section-header {
            font-size: 1.4rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# API Key file path
API_KEY_FILE = os.path.join(os.path.dirname(__file__), '.api_key.txt')
HISTORY_FILE = os.path.join(os.path.dirname(__file__), '.analysis_history.json')

# Function to load API key from file
def load_api_key():
    if os.path.exists(API_KEY_FILE):
        try:
            with open(API_KEY_FILE, 'r') as f:
                return f.read().strip()
        except:
            return ""
    return ""

# Function to save API key to file
def save_api_key(api_key):
    try:
        with open(API_KEY_FILE, 'w') as f:
            f.write(api_key)
        return True
    except:
        return False

# Function to load analysis history
def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []

# Function to save analysis to history
def save_to_history(analysis_type, content):
    try:
        history = load_history()
        
        # Keep only last 10 analyses
        if len(history) >= 10:
            history = history[-9:]
        
        history.append({
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'type': analysis_type,
            'content': content[:1000]  # Save first 1000 chars as summary
        })
        
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        st.warning(f"íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

        return False

# Function to delete history item
def delete_history_item(index):
    try:
        history = load_history()
        if 0 <= index < len(history):
            del history[index]
            with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            return True
        return False
    except:
        return False

# Function to get history summary
def get_history_summary(selected_indices=None):
    history = load_history()
    if not history:
        return "ì´ì „ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
    
    summary = "=== ì´ì „ ë¶„ì„ íˆìŠ¤í† ë¦¬ ===\n\n"
    
    # Filter by selected indices if provided
    if selected_indices is not None:
        target_history = [history[i] for i in selected_indices if 0 <= i < len(history)]
    else:
        target_history = history[-5:]  # Default to last 5
        
    if not target_history:
        return "ì„ íƒëœ ì´ì „ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
    for i, item in enumerate(target_history, 1):
        summary += f"{i}. [{item['timestamp']}] {item['type']}\n"
        summary += f"   ìš”ì•½: {item['content'][:200]}...\n\n"
    
    return summary

# Function to save as Word
def save_to_word(content):
    try:
        doc = Document()
        
        # Set style for Korean font
        style = doc.styles['Normal']
        style.font.name = 'Malgun Gothic'
        style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Malgun Gothic')
        
        # Add heading
        heading = doc.add_heading('ë¡œë´‡ ì‚°ì—… ë¶„ì„ ë¦¬í¬íŠ¸', 0)
        heading.style.font.name = 'Malgun Gothic'
        heading.style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Malgun Gothic')
        
        # Add timestamp
        p = doc.add_paragraph(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        p.style = doc.styles['Normal']
        
        doc.add_paragraph("-" * 50)
        
        # Add content
        for line in content.split('\n'):
            p = doc.add_paragraph(line)
            p.style = doc.styles['Normal']
        
        # Save to BytesIO
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    except Exception as e:
        st.error(f"Word ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# Function to save as PDF
def save_to_pdf(content):
    try:
        pdf = FPDF()
        pdf.add_page()
        
        # Add a Unicode font (using Malgun Gothic for Korean support)
        # Check for Windows font first, then try Linux fallback
        font_path = "C:/Windows/Fonts/malgun.ttf"
        if not os.path.exists(font_path):
            # Try common Linux Korean fonts or fallback
            possible_paths = [
                "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
                "/usr/share/fonts/nanum/NanumGothic.ttf"
            ]
            for path in possible_paths:
                if os.path.exists(path):
                    font_path = path
                    break
        
        if os.path.exists(font_path):
            pdf.add_font('Korean', '', font_path, uni=True)
            pdf.set_font('Korean', '', 11)
        else:
            st.warning("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            pdf.set_font("Arial", size=11)
            
        pdf.cell(0, 10, "ë¡œë´‡ ì‚°ì—… ë¶„ì„ ë¦¬í¬íŠ¸", new_x="LMARGIN", new_y="NEXT", align='C')
        pdf.cell(0, 10, f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", new_x="LMARGIN", new_y="NEXT", align='R')
        pdf.ln(10)
        
        # Split content by lines and write
        # Replace unsupported characters
        content = content.replace('\u2022', '-').replace('\u2013', '-').replace('\u2014', '-')
        
        for line in content.split('\n'):
            # Handle empty lines
            if not line.strip():
                pdf.ln(5)
                continue
            
            # Use multi_cell for automatic wrapping
            try:
                pdf.multi_cell(0, 8, line)
            except Exception:
                # Fallback for problematic lines (e.g. very long words)
                try:
                    pdf.multi_cell(0, 8, line[:100] + "...")
                except:
                    pass
            
        # Output to bytes
        return pdf.output(dest='S').encode('latin-1')
    except Exception as e:
        st.error(f"PDF ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# Initialize session state
if 'search_results' not in st.session_state:
    st.session_state.search_results = None
if 'ai_report' not in st.session_state:
    st.session_state.ai_report = None
if 'gemini_api_key' not in st.session_state:
    st.session_state.gemini_api_key = load_api_key()

# Sidebar configuration
with st.sidebar:
    st.markdown("### ğŸ”‘ API ì„¤ì •")
    api_key = st.text_input(
        "Gemini API Key", 
        value=st.session_state.gemini_api_key,
        type="password", 
        help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    # Save API key to session state and file
    if api_key and api_key != st.session_state.gemini_api_key:
        st.session_state.gemini_api_key = api_key
        if save_api_key(api_key):
            st.success("âœ… API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("âš ï¸ API í‚¤ ì €ì¥ ì‹¤íŒ¨")
    
    st.markdown("---")
    st.markdown("### âš™ï¸ ê²€ìƒ‰ í‚¤ì›Œë“œ ì„¤ì •")
    
    st.markdown("**ê·¸ë£¹ A (í•µì‹¬ - 70%)**")
    group_a_construction = st.text_area(
        "ê±´ì„¤ ë¡œë´‡ í‚¤ì›Œë“œ",
        value="ê±´ì„¤ ë¡œë´‡\nê±´ì„¤ í˜„ì¥ ìë™í™”\nìŠ¤ë§ˆíŠ¸ ê±´ì„¤ R&D\nê±´ì„¤ìš© ì›¨ì–´ëŸ¬ë¸” ë¡œë´‡",
        height=100
    )
    
    group_a_humanoid = st.text_area(
        "íœ´ë¨¸ë…¸ì´ë“œ í‚¤ì›Œë“œ",
        value="íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡\nì´ì¡±ë³´í–‰ ë¡œë´‡\ní…ŒìŠ¬ë¼ ì˜µí‹°ë¨¸ìŠ¤\ní”¼ê·œì–´ AI\në³´ìŠ¤í„´ ë‹¤ì´ë‚´ë¯¹ìŠ¤",
        height=120
    )
    
    st.markdown("**ê·¸ë£¹ B (ì¼ë°˜ - 30%)**")
    group_b_keywords = st.text_area(
        "ê¸°íƒ€ ë¡œë´‡ í‚¤ì›Œë“œ",
        value="í˜‘ë™ë¡œë´‡\në¬¼ë¥˜ ë¡œë´‡\nAMR\nì£¼ì°¨ ë¡œë´‡\nì œì¡°ì—… ë¡œë´‡",
        height=100
    )
    
    st.markdown("---")
    
    # History option
    st.markdown("### ğŸ“š ë¶„ì„ íˆìŠ¤í† ë¦¬")
    use_history = st.checkbox(
        "ì´ì „ ë¶„ì„ ê²°ê³¼ ì°¸ê³ ",
        value=True,
        help="ì²´í¬í•˜ë©´ ì´ì „ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤"
    )
    
    if use_history:
        history = load_history()
        if history:
            st.markdown("##### ğŸ•°ï¸ íˆìŠ¤í† ë¦¬ ê´€ë¦¬")
            st.markdown(f"<small>ì´ {len(history)}ê°œì˜ ë¶„ì„ ê¸°ë¡</small>", unsafe_allow_html=True)
            
            # Selected indices for context
            selected_history_indices = []
            
            # Iterate through history items (reverse order to show newest first)
            for i in range(len(history) - 1, -1, -1):
                item = history[i]
                with st.expander(f"{item['timestamp']} ({item['type']})"):
                    st.caption(f"ìš”ì•½: {item['content'][:100]}...")
                    
                    # Selection checkbox
                    if st.checkbox("ë¶„ì„ì— í¬í•¨", value=True, key=f"hist_sel_{i}"):
                        selected_history_indices.append(i)
                    
                    # Delete button
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"hist_del_{i}"):
                        if delete_history_item(i):
                            st.success("ì‚­ì œë¨")
                            time.sleep(0.5)
                            st.rerun()
        else:
            st.info("ğŸ“Š ì €ì¥ëœ ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤")
            selected_history_indices = []
    else:
        selected_history_indices = []
    
    st.markdown("---")
    st.markdown("### ğŸ“– ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
    2. í•„ìš”ì‹œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”
    3. ê° íƒ­ì—ì„œ ë¶„ì„ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    4. ë¶„ì„ ì™„ë£Œê¹Œì§€ ì•½ 1-2ë¶„ ì†Œìš”ë©ë‹ˆë‹¤
    """)

# Function to search news using DuckDuckGo
def search_news(keywords_list, max_results=5):
    """Search news using DuckDuckGo"""
    all_results = []
    seen_urls = set()
    
    ddgs = DDGS()
    
    for keyword in keywords_list:
        try:
            # Search with time filter (past week)
            results = ddgs.text(
                keyword,
                region='kr-kr',
                safesearch='off',
                timelimit='w',  # Past week
                max_results=max_results
            )
            
            for result in results:
                url = result.get('href', '')
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    all_results.append({
                        'title': result.get('title', ''),
                        'snippet': result.get('body', ''),
                        'url': url,
                        'keyword': keyword
                    })
            
            # Small delay to avoid rate limiting
            time.sleep(0.5)
            
        except Exception as e:
            st.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ (í‚¤ì›Œë“œ: {keyword}): {str(e)}")
    return all_results

# Function to generate AI report using Gemini
def generate_ai_report(group_a_news, group_b_news, api_key, use_history=False, selected_indices=None):
    """Generate analysis report using Gemini AI"""
    try:
        # Configure Gemini API
        genai.configure(api_key=api_key)
        
        # Get history if requested
        history_context = ""
        if use_history:
            history_context = f"\n\n**ì´ì „ ë¶„ì„ ì°¸ê³ :**\n{get_history_summary(selected_indices)}\n"
        
        # System instruction
        system_instruction = f"""
ë„ˆëŠ” ë¡œë´‡ ì‚°ì—… ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼. ì œê³µëœ ë‰´ìŠ¤ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•˜ì§€ ë§ê³ , ë„ˆì˜ ì „ë¬¸ì ì¸ ë¶„ì„ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì•¼ í•´.
{history_context}
**í•µì‹¬ ì§€ì¹¨:**
1. ì „ì²´ ë¦¬í¬íŠ¸ì˜ **70%**ëŠ” 'ê±´ì„¤ ë¡œë´‡ì˜ í˜„ì¥ ì ìš©'ê³¼ 'íœ´ë¨¸ë…¸ì´ë“œì˜ ê¸°ìˆ  ì§„ì²™(ì œì–´, AI, í•˜ë“œì›¨ì–´)'ì— ì§‘ì¤‘
2. ë‘ ë¶„ì•¼ì˜ ìœµí•© ê°€ëŠ¥ì„±(ì˜ˆ: íœ´ë¨¸ë…¸ì´ë“œì˜ ê±´ì„¤ í˜„ì¥ íˆ¬ì…)ì„ ì ê·¹ì ìœ¼ë¡œ ë¶„ì„
3. ë‚˜ë¨¸ì§€ 30%ëŠ” ê¸°íƒ€ ë¡œë´‡ ì‹œì¥ ë™í–¥
4. **ì¤‘ìš”**: ë‰´ìŠ¤ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , íŠ¸ë Œë“œë¥¼ íŒŒì•…í•˜ê³  ë„ˆì˜ ë¶„ì„ì„ ì œì‹œí•´
5. ì´ì „ ë¶„ì„ì´ ìˆë‹¤ë©´, íŠ¸ë Œë“œ ë³€í™”ì™€ ì—°ì†ì„±ì„ ë¶„ì„í•´

**ë¦¬í¬íŠ¸ êµ¬ì¡°:**

## 1. ğŸ—ï¸ ê±´ì„¤ ë¡œë´‡ & íœ´ë¨¸ë…¸ì´ë“œ ì‹¬ì¸µ ë¶„ì„ (70%)

### 1.1 ê±´ì„¤ ë¡œë´‡ í˜„ì¥ ì ìš© ë¶„ì„
- í˜„ì¬ ê¸°ìˆ  ìˆ˜ì¤€ê³¼ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë¶„ì„
- ì£¼ìš” ê¸°ìˆ ì  ê³¼ì œì™€ í•´ê²° ë°©í–¥
- ì‹œì¥ ì„±ì¥ ê°€ëŠ¥ì„± í‰ê°€

### 1.2 íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ ê¸°ìˆ  ì§„ì²™
- ì œì–´ ê¸°ìˆ ì˜ ìµœì‹  ë™í–¥ (ë³´í–‰, ê· í˜•, ì¡°ì‘)
- AI í†µí•© í˜„í™© (ë¹„ì „, ììœ¨ì„±, í•™ìŠµ)
- í•˜ë“œì›¨ì–´ í˜ì‹  (ì•¡ì¶”ì—ì´í„°, ì„¼ì„œ, ë°°í„°ë¦¬)

### 1.3 ìœµí•© ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
- íœ´ë¨¸ë…¸ì´ë“œì˜ ê±´ì„¤ í˜„ì¥ íˆ¬ì… ê°€ëŠ¥ì„±
- ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ê³¼ í˜„ì¬ ê²©ì°¨
- ì˜ˆìƒ íƒ€ì„ë¼ì¸ê³¼ ì„ ë„ ê¸°ì—…

### 1.4 ì£¼ìš” ê¸°ì—… ë° í”„ë¡œì íŠ¸ í‰ê°€
- í•µì‹¬ í”Œë ˆì´ì–´ ë¶„ì„ (í…ŒìŠ¬ë¼, ë³´ìŠ¤í„´ë‹¤ì´ë‚´ë¯¹ìŠ¤, Figure AI ë“±)
- íˆ¬ì ë™í–¥ê³¼ ì „ëµì  ë°©í–¥

## 2. ğŸ¤– ê¸°íƒ€ ë¡œë´‡ ì‚°ì—… ë™í–¥ (30%)
- í˜‘ë™ë¡œë´‡, ë¬¼ë¥˜ë¡œë´‡, AMR ë“±ì˜ ì£¼ìš” íŠ¸ë Œë“œ
- ì‹œì¥ ì„±ì¥ ë™ë ¥ê³¼ ì œì•½ ìš”ì¸

## 3. ğŸ’¡ AI ì „ë§ ë° íˆ¬ì ì¸ì‚¬ì´íŠ¸
- **ë‹¨ê¸° ì „ë§ (6ê°œì›”~1ë…„)**: ì˜ˆìƒë˜ëŠ” ì£¼ìš” ì´ë²¤íŠ¸ì™€ ê¸°ìˆ  ë°œí‘œ
- **ì¤‘ê¸° ì „ë§ (1~3ë…„)**: ì‹œì¥ êµ¬ì¡° ë³€í™”ì™€ ê¸°ìˆ  ì„±ìˆ™ë„
- **ì¥ê¸° ì „ë§ (3~5ë…„)**: ì‚°ì—… íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ ê°€ëŠ¥ì„±
- **íˆ¬ì ê´€ì **: ì£¼ëª©í•´ì•¼ í•  ê¸°ì—…, ê¸°ìˆ , ì‹œì¥ ì„¸ê·¸ë¨¼íŠ¸
- **ë¦¬ìŠ¤í¬ ìš”ì¸**: ê¸°ìˆ ì /ê·œì œì /ì‹œì¥ ë¦¬ìŠ¤í¬

**ì‘ì„± ìŠ¤íƒ€ì¼:**
- ì „ë¬¸ì ì´ê³  ë¶„ì„ì ì¸ í†¤
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì‚¬ë¡€ ì¸ìš©
- ëª…í™•í•œ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì „ë§
- ë¶ˆí™•ì‹¤ì„±ì´ ìˆëŠ” ë¶€ë¶„ì€ ì†”ì§í•˜ê²Œ ì–¸ê¸‰
"""
        
        # Prepare news data
        group_a_text = "\n\n".join([
            f"ì œëª©: {news['title']}\në‚´ìš©: {news['snippet']}\nì¶œì²˜: {news['url']}"
            for news in group_a_news
        ])
        
        group_b_text = "\n\n".join([
            f"ì œëª©: {news['title']}\në‚´ìš©: {news['snippet']}\nì¶œì²˜: {news['url']}"
            for news in group_b_news
        ])
        
        # Create full prompt
        full_prompt = f"""{system_instruction}

ë‹¤ìŒ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ê°„ ë¡œë´‡ ì‚°ì—… ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ê·¸ë£¹ A - ê±´ì„¤ ë¡œë´‡ & íœ´ë¨¸ë…¸ì´ë“œ ë‰´ìŠ¤ (í•µì‹¬)]
{group_a_text}

[ê·¸ë£¹ B - ê¸°íƒ€ ë¡œë´‡ ë‰´ìŠ¤]
{group_b_text}

í˜„ì¬ ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}
ë¶„ì„ ê¸°ê°„: ìµœê·¼ 1ì£¼ì¼
"""
        
        # Use google-generativeai library (same as stock advisor)
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(full_prompt)
        
        # Save to history
        if response.text:
            save_to_history("ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„", response.text)
        
        return response.text
        
    except Exception as e:
        st.error(f"AI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# Function to extract text from PDF
def extract_pdf_text(pdf_file):
    """Extract text from PDF file"""
    try:
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"PDF ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

# Function to analyze uploaded files
def analyze_files(files, api_key):
    """Analyze uploaded files using Gemini AI"""
    try:
        genai.configure(api_key=api_key)
        
        all_text = ""
        for file in files:
            if file.type == "application/pdf":
                text = extract_pdf_text(file)
                if text:
                    all_text += f"\n\n=== {file.name} ===\n{text}"
            elif file.type == "text/plain":
                text = file.read().decode('utf-8')
                all_text += f"\n\n=== {file.name} ===\n{text}"
        
        if not all_text:
            return None
        
        prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì—¬ ë¡œë´‡ ì‚°ì—… ê´€ì ì—ì„œ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš© ìš”ì•½
2. ë¡œë´‡ ì‚°ì—…ê³¼ì˜ ì—°ê´€ì„± ë¶„ì„
3. ê¸°ìˆ ì  ì‹œì‚¬ì  ë° íŠ¸ë Œë“œ
4. ë¹„ì¦ˆë‹ˆìŠ¤ ë° íˆ¬ì ì¸ì‚¬ì´íŠ¸
5. í–¥í›„ ì „ë§ ë° ê¶Œê³ ì‚¬í•­

**ë¬¸ì„œ ë‚´ìš©:**
{all_text}

**ì‘ì„± ìŠ¤íƒ€ì¼:**
- ì „ë¬¸ì ì´ê³  ë¶„ì„ì ì¸ í†¤
- êµ¬ì²´ì ì¸ ë‚´ìš© ì¸ìš©
- ëª…í™•í•œ êµ¬ì¡°í™”
- ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
"""
        
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(prompt)
        
        # Save to history
        if response.text:
            save_to_history("íŒŒì¼ ë¶„ì„", response.text)
        
        return response.text
        
    except Exception as e:
        st.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return None

# Function to generate integrated report
def generate_integrated_report(news_report, file_report, api_key):
    """Generate integrated analysis combining news and file analysis"""
    try:
        genai.configure(api_key=api_key)
        
        prompt = f"""
ë‹¤ìŒ ë‘ ê°€ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¶„ì„ 1: ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼**
{news_report}

**ë¶„ì„ 2: íŒŒì¼ ë¶„ì„ ê²°ê³¼**
{file_report}

**í†µí•© ë¦¬í¬íŠ¸ ì‘ì„± ìš”êµ¬ì‚¬í•­:**

## 1. ğŸ”„ êµì°¨ ë¶„ì„ ë° ì‹œë„ˆì§€
- ë‰´ìŠ¤ íŠ¸ë Œë“œì™€ íŒŒì¼ ë‚´ìš©ì˜ ì—°ê´€ì„± ë¶„ì„
- ìƒí˜¸ ë³´ì™„ì ì¸ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
- ì¼ì¹˜í•˜ëŠ” ë¶€ë¶„ê³¼ ì°¨ì´ì  ë¶„ì„

## 2. ğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ í†µí•©
- ë‘ ë¶„ì„ì—ì„œ ê³µí†µìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” í•µì‹¬ íŠ¸ë Œë“œ
- ê° ë¶„ì„ì—ì„œë§Œ ë‚˜íƒ€ë‚˜ëŠ” ë…íŠ¹í•œ ì¸ì‚¬ì´íŠ¸
- í†µí•©ì  ê´€ì ì—ì„œì˜ ì‹œì¥ ì „ë§

## 3. ğŸ’¡ ì „ëµì  ì œì–¸
- ë‰´ìŠ¤ì™€ ë¬¸ì„œ ë¶„ì„ì„ ì¢…í•©í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ
- ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ê´€ì ì˜ ê¶Œê³ ì‚¬í•­
- ì£¼ëª©í•´ì•¼ í•  ê¸°íšŒì™€ ë¦¬ìŠ¤í¬

## 4. ğŸ“Š ì¢…í•© ê²°ë¡ 
- ë¡œë´‡ ì‚°ì—…ì˜ í˜„ì¬ ìƒí™© ì¢…í•©
- í–¥í›„ ì „ë§ ë° ì˜ˆì¸¡
- ìµœì¢… íˆ¬ì/ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸

**ì‘ì„± ìŠ¤íƒ€ì¼:**
- ë‘ ë¶„ì„ì„ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°
- êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ ì˜ˆì‹œ ì œì‹œ
- ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì–¸
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ í˜•ì‹
"""
        
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(prompt)
        
        # Save to history
        if response.text:
            save_to_history("í†µí•© ë¶„ì„", response.text)
        
        return response.text
        
    except Exception as e:
        st.error(f"í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return None

# Main content with tabs
st.markdown('<div class="main-header">ğŸ¤– ë¡œë´‡ ì‚°ì—… ë¶„ì„ í”Œë«í¼</div>', unsafe_allow_html=True)

tab1, tab2, tab3 = st.tabs(["ğŸ“° ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„", "ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ë¶„ì„", "ğŸ”„ í†µí•© ë¶„ì„"])

# Tab 1: Weekly News Analysis
with tab1:
    st.markdown("**ê±´ì„¤ ë¡œë´‡**ê³¼ **íœ´ë¨¸ë…¸ì´ë“œ**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ë¡œë´‡ ì‚°ì—… ì‹¬ì¸µ ë¶„ì„")
    
    news_analysis_button = st.button("ğŸ” ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘", type="primary", key="news_analysis_btn")
    
    # Generate report when button is clicked
    if news_analysis_button:
        if not api_key:
            st.error("âš ï¸ Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            # Parse keywords
            construction_keywords = [k.strip() for k in group_a_construction.split('\n') if k.strip()]
            humanoid_keywords = [k.strip() for k in group_a_humanoid.split('\n') if k.strip()]
            other_keywords = [k.strip() for k in group_b_keywords.split('\n') if k.strip()]
            
            group_a_all = construction_keywords + humanoid_keywords
            
            # Search progress
            with st.spinner('ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘... (ì•½ 30-60ì´ˆ ì†Œìš”)'):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Search Group A (high priority)
                status_text.text("ê·¸ë£¹ A ê²€ìƒ‰ ì¤‘ (ê±´ì„¤ ë¡œë´‡ & íœ´ë¨¸ë…¸ì´ë“œ)...")
                group_a_results = search_news(group_a_all, max_results=5)
                progress_bar.progress(60)
                
                # Search Group B
                status_text.text("ê·¸ë£¹ B ê²€ìƒ‰ ì¤‘ (ê¸°íƒ€ ë¡œë´‡)...")
                group_b_results = search_news(other_keywords, max_results=3)
                progress_bar.progress(80)
                
                status_text.text("ê²€ìƒ‰ ì™„ë£Œ!")
                progress_bar.progress(100)
                time.sleep(0.5)
                progress_bar.empty()
                status_text.empty()
            
            # Store results
            st.session_state.search_results = {
                'group_a': group_a_results,
                'group_b': group_b_results
            }
            
            # Generate AI report
            if group_a_results or group_b_results:
                with st.spinner('ğŸ¤– AI ë¶„ì„ ì¤‘... (ì•½ 30ì´ˆ ì†Œìš”)'):
                    ai_report = generate_ai_report(
                        group_a_results, 
                        group_b_results, 
                        api_key, 
                        use_history=use_history,
                        selected_indices=selected_history_indices
                    )
                    st.session_state.ai_report = ai_report
                
                st.success(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ! (ê·¸ë£¹ A: {len(group_a_results)}ê±´, ê·¸ë£¹ B: {len(group_b_results)}ê±´)")
            else:
                st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë³€ê²½í•´ë³´ì„¸ìš”.")
    
    # Display AI report
    if st.session_state.ai_report:
        st.markdown("---")
        st.markdown('<div class="section-header">ğŸ“Š AI ë¶„ì„ ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
        
        with st.container():
            st.markdown(st.session_state.ai_report)
            
            # Export buttons
            st.markdown("### ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥")
            col1, col2 = st.columns(2)
            with col1:
                docx_data = save_to_word(st.session_state.ai_report)
                if docx_data:
                    st.download_button(
                        label="ğŸ“„ Wordë¡œ ì €ì¥",
                        data=docx_data,
                        file_name="ì£¼ê°„_ë¡œë´‡_ì‚°ì—…_ë¶„ì„.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="save_news_word"
                    )
            with col2:
                pdf_data = save_to_pdf(st.session_state.ai_report)
                if pdf_data:
                    st.download_button(
                        label="ğŸ“‘ PDFë¡œ ì €ì¥",
                        data=pdf_data,
                        file_name="ì£¼ê°„_ë¡œë´‡_ì‚°ì—…_ë¶„ì„.pdf",
                        mime="application/pdf",
                        key="save_news_pdf"
                    )
        
        # Show source count at bottom
        if st.session_state.search_results:
            results = st.session_state.search_results
            total_sources = len(results.get('group_a', [])) + len(results.get('group_b', []))
            st.info(f"ğŸ“° ë¶„ì„ì— ì‚¬ìš©ëœ ë‰´ìŠ¤ ì†ŒìŠ¤: ì´ {total_sources}ê±´ (ê±´ì„¤/íœ´ë¨¸ë…¸ì´ë“œ: {len(results.get('group_a', []))}ê±´, ê¸°íƒ€: {len(results.get('group_b', []))}ê±´)")

# Tab 2: File Upload Analysis
with tab2:
    st.markdown("### ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ë¶„ì„")
    st.markdown("PDF ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¡œë´‡ ì‚°ì—… ê´€ì ì—ì„œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # Initialize session state for file analysis
    if 'file_analysis_report' not in st.session_state:
        st.session_state.file_analysis_report = None
    
    uploaded_files = st.file_uploader(
        "íŒŒì¼ ì„ íƒ (PDF, TXT)",
        type=['pdf', 'txt'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )
    
    analyze_button = st.button("ğŸ” íŒŒì¼ ë¶„ì„ ì‹œì‘", type="primary", key="analyze_files_btn")
    
    if analyze_button:
        if not api_key:
            st.error("âš ï¸ Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif not uploaded_files:
            st.error("âš ï¸ ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner('ğŸ“„ íŒŒì¼ ë¶„ì„ ì¤‘... (ì•½ 30-60ì´ˆ ì†Œìš”)'):
                file_report = analyze_files(uploaded_files, api_key)
                st.session_state.file_analysis_report = file_report
            
            if file_report:
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ({len(uploaded_files)}ê°œ íŒŒì¼)")
    
    # Display file analysis report
    if st.session_state.file_analysis_report:
        st.markdown("---")
        st.markdown('<div class="section-header">ğŸ“Š íŒŒì¼ ë¶„ì„ ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
        
        with st.container():
            st.markdown(st.session_state.file_analysis_report)
            
            # Export buttons
            st.markdown("### ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥")
            col1, col2 = st.columns(2)
            with col1:
                docx_data = save_to_word(st.session_state.file_analysis_report)
                if docx_data:
                    st.download_button(
                        label="ğŸ“„ Wordë¡œ ì €ì¥",
                        data=docx_data,
                        file_name="íŒŒì¼_ë¶„ì„_ë¦¬í¬íŠ¸.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="save_file_word"
                    )
            with col2:
                pdf_data = save_to_pdf(st.session_state.file_analysis_report)
                if pdf_data:
                    st.download_button(
                        label="ğŸ“‘ PDFë¡œ ì €ì¥",
                        data=pdf_data,
                        file_name="íŒŒì¼_ë¶„ì„_ë¦¬í¬íŠ¸.pdf",
                        mime="application/pdf",
                        key="save_file_pdf"
                    )
        
        if uploaded_files:
            st.info(f"ğŸ“ ë¶„ì„ëœ íŒŒì¼: {', '.join([f.name for f in uploaded_files])}")

# Tab 3: Integrated Analysis
with tab3:
    st.markdown("### ğŸ”„ í†µí•© ë¶„ì„")
    st.markdown("ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„ê³¼ íŒŒì¼ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì¢…í•©ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
    
    # Initialize session state for integrated analysis
    if 'integrated_report' not in st.session_state:
        st.session_state.integrated_report = None
    
    # Check if both analyses are available
    has_news = st.session_state.ai_report is not None
    has_files = st.session_state.file_analysis_report is not None
    
    if has_news and has_files:
        st.success("âœ… ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„ê³¼ íŒŒì¼ ë¶„ì„ ê²°ê³¼ê°€ ëª¨ë‘ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        integrate_button = st.button("ğŸ”„ í†µí•© ë¶„ì„ ì‹œì‘", type="primary", key="integrate_btn")
        
        if integrate_button:
            if not api_key:
                st.error("âš ï¸ Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner('ğŸ”„ í†µí•© ë¶„ì„ ì¤‘... (ì•½ 30-60ì´ˆ ì†Œìš”)'):
                    integrated_report = generate_integrated_report(
                        st.session_state.ai_report,
                        st.session_state.file_analysis_report,
                        api_key
                    )
                    st.session_state.integrated_report = integrated_report
                
                if integrated_report:
                    st.success("âœ… í†µí•© ë¶„ì„ ì™„ë£Œ!")
        
        # Display integrated report
        if st.session_state.integrated_report:
            st.markdown("---")
            st.markdown('<div class="section-header">ğŸ“Š í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
            
            with st.container():
                st.markdown(st.session_state.integrated_report)
                
                # Export buttons
                st.markdown("### ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥")
                col1, col2 = st.columns(2)
                with col1:
                    docx_data = save_to_word(st.session_state.integrated_report)
                    if docx_data:
                        st.download_button(
                            label="ğŸ“„ Wordë¡œ ì €ì¥",
                            data=docx_data,
                            file_name="í†µí•©_ë¶„ì„_ë¦¬í¬íŠ¸.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key="save_integrated_word"
                        )
                with col2:
                    pdf_data = save_to_pdf(st.session_state.integrated_report)
                    if pdf_data:
                        st.download_button(
                            label="ğŸ“‘ PDFë¡œ ì €ì¥",
                            data=pdf_data,
                            file_name="í†µí•©_ë¶„ì„_ë¦¬í¬íŠ¸.pdf",
                            mime="application/pdf",
                            key="save_integrated_pdf"
                        )
            
            # Show summary
            st.info("ğŸ’¡ ì´ ë¦¬í¬íŠ¸ëŠ” ì£¼ê°„ ë‰´ìŠ¤ íŠ¸ë Œë“œì™€ ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
    
    elif has_news and not has_files:
        st.warning("âš ï¸ íŒŒì¼ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 'ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ë¶„ì„' íƒ­ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.")
    elif not has_news and has_files:
        st.warning("âš ï¸ ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 'ğŸ“° ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„' íƒ­ì—ì„œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        st.info("â„¹ï¸ í†µí•© ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë¨¼ì € ë‹¤ìŒ ì‘ì—…ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”:")
        st.markdown("""
        1. ì£¼ê°„ ë‰´ìŠ¤ ë¶„ì„ íƒ­ì—ì„œ ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±
        2. íŒŒì¼ ì—…ë¡œë“œ ë¶„ì„ íƒ­ì—ì„œ íŒŒì¼ ë¶„ì„ ì™„ë£Œ
        3. ì´ íƒ­ìœ¼ë¡œ ëŒì•„ì™€ì„œ í†µí•© ë¶„ì„ ì‹œì‘ ë²„íŠ¼ í´ë¦­
        """)


# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #888; font-size: 0.9rem;">
    <p>Robot Industry Analysis Platform | Powered by Gemini AI & DuckDuckGo</p>
    <p>Generated: {}</p>
</div>
""".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')), unsafe_allow_html=True)
